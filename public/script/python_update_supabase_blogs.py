import json
import pandas as pd
from supabase import create_client, Client
from dotenv import load_dotenv
import os
from tqdm import tqdm


# ----------------------------------------------------------
# 1. é…ç½®ä½ çš„ Supabase
# ----------------------------------------------------------
load_dotenv()

url: str = os.environ.get("SUPABASE_URL")
key: str = os.environ.get("SUPABASE_KEY")

# åˆå§‹åŒ– Supabase å®¢æˆ·ç«¯
supabase: Client = create_client(url, key)

# ----------------------------------------------------------
# 2. è¯»å–åˆå¹¶åçš„ JSON æ–‡ä»¶
# ----------------------------------------------------------
with open("gutenberg_metadata_by_id.json", "r", encoding="utf-8") as f:
    data = json.load(f)

# è½¬æˆåˆ—è¡¨å½¢å¼ï¼Œæ–¹ä¾¿æ‰¹é‡æ“ä½œ
records = []
for gid, item in data.items():
    records.append({
        "id": int(gid),
        "title": item.get("title"),
        "authors": [{"name":item.get("author"),"avatar":"/static/images/avatar/2.jpg"}] if item.get("author") else None,
        "description": item.get("subjects")
    })

print("å¾…æ›´æ–°è®°å½•æ•°é‡ï¼š", len(records))
print(records[0])

# ----------------------------------------------------------
# 3. æŒ‰ 500 æ¡åˆ†æ‰¹æ›´æ–°
# ----------------------------------------------------------
BATCH_SIZE = 1

for i in tqdm(range(69902, len(records), BATCH_SIZE), desc="Updating Supabase"):
    batch = records[i:i + BATCH_SIZE]

    # æ‰¹é‡é€æ¡ updateï¼ˆåªæ›´æ–°å·²æœ‰çš„ idï¼‰
    for row in batch:
        supabase.table("blogs").update({
            "title": row["title"],
            "authors": row["authors"],
            "description": row["description"],
        }).eq("id", row["id"]).execute()


print("ğŸ‰ å…¨éƒ¨æ›´æ–°å®Œæ¯•ï¼")

